{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain-ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of unique scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "scenarios_file = \"scenarios.csv\"\n",
    "unique_scenarios_file = \"scenarios_unique.csv\"\n",
    "\n",
    "def select_unique_scenarios(input, output):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input)\n",
    "\n",
    "    # Strip unnecessary leading and trailing spaces\n",
    "    df['Scenario ID'] = df['Scenario ID'].str.strip()\n",
    "    df['User'] = df['User'].str.strip()\n",
    "\n",
    "    # Select unique Scenario IDs\n",
    "    unique = df.drop_duplicates(subset=['Scenario ID'], keep='first')[\n",
    "        ['Scenario ID', 'User']]\n",
    "\n",
    "    # Save the unique rows to a new CSV file\n",
    "    unique.to_csv(output, index=False, sep=\";\")\n",
    "\n",
    "    print(f\"Unique scenarios saved to {output}\")\n",
    "\n",
    "\n",
    "select_unique_scenarios(scenarios_file, unique_scenarios_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_llm_prompt(scenario_id, scenarios_df, threats_df, vulnerabilities_df):\n",
    "    \"\"\"\n",
    "    Generates a formatted LLM prompt based on the given scenario, threats, and vulnerabilities.\n",
    "    \n",
    "    Args:\n",
    "        scenario_id (str): The scenario ID to pull the correct description.\n",
    "        scenarios_df (pd.DataFrame): DataFrame containing scenarios data.\n",
    "        threats_df (pd.DataFrame): DataFrame containing threat data.\n",
    "        vulnerabilities_df (pd.DataFrame): DataFrame containing vulnerability data.\n",
    "        \n",
    "    Returns:\n",
    "        str: The LLM prompt formatted as a string.\n",
    "    \"\"\"\n",
    "    # Get the specific scenario description\n",
    "    scenario_row = scenarios_df[scenarios_df['Scenario ID'] == scenario_id].iloc[0]\n",
    "    scenario_description = scenario_row['User']  # You can use 'User' or another column based on need\n",
    "    \n",
    "    # Get the risk and vulnerability descriptions\n",
    "    risk_description = scenario_row['Assistant - Risk description'] if 'Assistant - Risk description' in scenario_row else \"No risk description available.\"\n",
    "    vulnerability_description = scenario_row['Assistant - Vulnerability description'] if 'Assistant - Vulnerability description' in scenario_row else \"No vulnerability description available.\"\n",
    "    \n",
    "    # Format the Threats section\n",
    "    threats_text = \"\\n\".join([\n",
    "        f\"THREAT ID: {row['THREAT ID']}\\nTHREAT: {row['THREAT']}\\nDESCRIPTION: {row['DESCRIPTION']}\"\n",
    "        for _, row in threats_df.iterrows()\n",
    "    ])\n",
    "    #print(threats_df)\n",
    "    \n",
    "    # Format the Vulnerabilities section\n",
    "    vulnerabilities_text = \"\\n\".join([\n",
    "        f\"VULNERABILITY ID: {row['ID']}\\nVULNERABILITY: {row['VULNERABILITY']}\\nDESCRIPTION: {row['DESCRIPTION']}\"\n",
    "        for _, row in vulnerabilities_df.iterrows()\n",
    "    ])\n",
    "    #print(vulnerabilities_text)\n",
    "    # Format the complete LLM prompt\n",
    "    prompt = f\"\"\"\n",
    "\n",
    "\n",
    "    Scenario: \"{scenario_description}\"\n",
    "\n",
    "    \n",
    "    Beginning of list of Threats\n",
    "    Threats:\n",
    "    {threats_text}\n",
    "\n",
    "    End list of Threats\n",
    "\n",
    "\n",
    "    ROLE: You are an assistant in security risk analysis. \n",
    "\n",
    "    For each given scenario, determine which **threats** and **vulnerabilities** are present. \n",
    "    You have access to two lists: one for **threats** and another for **vulnerabilities**. Use these lists to identify the relevant threats and vulnerabilities for each scenario.\n",
    "\n",
    "    ### **Instructions:**\n",
    "    1. For each scenario provided, identify which threats and vulnerabilities from the lists match the scenario.\n",
    "    2. If a **threat** or **vulnerability** applies, include its description, explaining why it is relevant to the scenario.\n",
    "    3. Provide a **JSON** output with the following structure:\n",
    "    - **Threats**: A list of threats that apply to the scenario.\n",
    "    - **Vulnerabilities**: A list of vulnerabilities that apply to the scenario.\n",
    "\n",
    "    Each item in the list should contain:\n",
    "    - **ThreatID** / **VulnID**: The identifier for the threat/vulnerability.\n",
    "    - **Threat** / **Vulnerability**: The name of the threat/vulnerability.\n",
    "    - **Description**: A detailed explanation of the threat/vulnerability.\n",
    "\n",
    "    **If no threats or vulnerabilities apply**, respond with an empty array for that category.\n",
    "    \"Generate a JSON object with the following information.\"\n",
    "    ### **Format of the Response:**\n",
    "        {{\n",
    "            \"ScenarioID\": \"[Scenario ID]\",\n",
    "            \"Threats\": [\n",
    "                {{\n",
    "                    \"ThreatID\": \"[Threat ID]\",\n",
    "                    \"Threat\": \"[Threat Name]\",\n",
    "                    \"Description\": \"[Threat Description]\"\n",
    "                }}\n",
    "            ]\n",
    "            \n",
    "        }}\n",
    "        \"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def generate_prompts_for_all_scenarios(scenarios_df, threats_df, vulnerabilities_df):\n",
    "    \"\"\"\n",
    "    Generate LLM prompts for all scenarios in the CSV.\n",
    "\n",
    "    Args:\n",
    "        scenarios_df (pd.DataFrame): DataFrame containing scenarios.\n",
    "        threats_df (pd.DataFrame): DataFrame containing threats.\n",
    "        vulnerabilities_df (pd.DataFrame): DataFrame containing vulnerabilities.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of prompts for each scenario.\n",
    "    \"\"\"\n",
    "    prompts = []\n",
    "    for scenario_id in scenarios_df['Scenario ID']:\n",
    "        prompt = generate_llm_prompt(scenario_id, scenarios_df, threats_df, vulnerabilities_df)\n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    return prompts\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Load the CSV files into DataFrames with the correct delimiter (semicolon)\n",
    "scenarios_df = pd.read_csv(unique_scenarios_file, delimiter=';')\n",
    "threats_df = pd.read_csv('threat.csv', delimiter=';')\n",
    "vulnerabilities_df = pd.read_csv('vulnerability.csv', delimiter=';')\n",
    "\n",
    "# Clean the column names (strip spaces)\n",
    "scenarios_df.columns = scenarios_df.columns.str.strip()\n",
    "threats_df.columns = threats_df.columns.str.strip()\n",
    "vulnerabilities_df.columns = vulnerabilities_df.columns.str.strip()\n",
    "\n",
    "# Generate prompts for all scenarios\n",
    "prompts = generate_prompts_for_all_scenarios(scenarios_df, threats_df, vulnerabilities_df)\n",
    "\n",
    "# Print the first generated prompt as an example\n",
    "print(prompts[0])  # Example: Print the first prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "import csv\n",
    "\n",
    "answer_limit = 3\n",
    "csv_filename = \"answers.csv\"\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "Answer: Lets think step by step\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = OllamaLLM(model=\"marco-o1\")\n",
    "chain = prompt | model\n",
    "\n",
    "def generate_answer_for_prompt(prompt, chain):\n",
    "    answer = (chain.invoke({\"question\": prompt}))\n",
    "    print(answer)\n",
    "    return answer\n",
    "\n",
    "def generate_answers_for_all_prompts(prompts, chain, limit, answer_file):\n",
    "    limit = min(limit, len(prompts))\n",
    "\n",
    "    for i in range(limit):\n",
    "        question = prompts[i]\n",
    "        print(f\"Generating {i+1}/{limit}\")\n",
    "        answer = generate_answer_for_prompt(question, chain)\n",
    "\n",
    "        with open(answer_file, mode=\"a\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([answer])  # Writing question-answer pair\n",
    "\n",
    "        print(f\"Answer saved to {answer_file}\")\n",
    "\n",
    "generate_answers_for_all_prompts(prompts, chain, answer_limit, csv_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
