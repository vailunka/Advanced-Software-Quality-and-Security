{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_llm_prompt(scenario_id, scenarios_df, threats_df, vulnerabilities_df):\n",
    "    \"\"\"\n",
    "    Generates a formatted LLM prompt based on the given scenario, threats, and vulnerabilities.\n",
    "    \n",
    "    Args:\n",
    "        scenario_id (str): The scenario ID to pull the correct description.\n",
    "        scenarios_df (pd.DataFrame): DataFrame containing scenarios data.\n",
    "        threats_df (pd.DataFrame): DataFrame containing threat data.\n",
    "        vulnerabilities_df (pd.DataFrame): DataFrame containing vulnerability data.\n",
    "        \n",
    "    Returns:\n",
    "        str: The LLM prompt formatted as a string.\n",
    "    \"\"\"\n",
    "    # Get the specific scenario description\n",
    "    scenario_row = scenarios_df[scenarios_df['Scenario ID'] == scenario_id].iloc[0]\n",
    "    scenario_description = scenario_row['User']  # You can use 'User' or another column based on need\n",
    "    \n",
    "    # Get the risk and vulnerability descriptions\n",
    "    risk_description = scenario_row['Assistant - Risk description'] if 'Assistant - Risk description' in scenario_row else \"No risk description available.\"\n",
    "    vulnerability_description = scenario_row['Assistant - Vulnerability description'] if 'Assistant - Vulnerability description' in scenario_row else \"No vulnerability description available.\"\n",
    "    \n",
    "    # Format the Threats section\n",
    "    threats_text = \"\\n\".join([\n",
    "        f\"THREAT ID: {row['THREAT ID']}\\nTHREAT: {row['THREAT']}\\nDESCRIPTION: {row['DESCRIPTION']}\"\n",
    "        for _, row in threats_df.iterrows()\n",
    "    ])\n",
    "    #print(threats_df)\n",
    "    \n",
    "    # Format the Vulnerabilities section\n",
    "    vulnerabilities_text = \"\\n\".join([\n",
    "        f\"VULNERABILITY ID: {row['ID']}\\nVULNERABILITY: {row['VULNERABILITY']}\\nDESCRIPTION: {row['DESCRIPTION']}\"\n",
    "        for _, row in vulnerabilities_df.iterrows()\n",
    "    ])\n",
    "    #print(vulnerabilities_text)\n",
    "    # Format the complete LLM prompt\n",
    "    prompt = f\"\"\"\n",
    "\n",
    "\n",
    "    Scenario: \"{scenario_description}\"\n",
    "\n",
    "    \n",
    "    Beginning of list of Threats\n",
    "    Threats:\n",
    "    {threats_text}\n",
    "\n",
    "    End list of Threats\n",
    "\n",
    "\n",
    "    ROLE: You are an assistant in security risk analysis. \n",
    "\n",
    "    For each given scenario, determine which **threats** and **vulnerabilities** are present. \n",
    "    You have access to two lists: one for **threats** and another for **vulnerabilities**. Use these lists to identify the relevant threats and vulnerabilities for each scenario.\n",
    "\n",
    "    ### **Instructions:**\n",
    "    1. For each scenario provided, identify which threats and vulnerabilities from the lists match the scenario.\n",
    "    2. If a **threat** or **vulnerability** applies, include its description, explaining why it is relevant to the scenario.\n",
    "    3. Provide a **JSON** output with the following structure:\n",
    "    - **Threats**: A list of threats that apply to the scenario.\n",
    "    - **Vulnerabilities**: A list of vulnerabilities that apply to the scenario.\n",
    "\n",
    "    Each item in the list should contain:\n",
    "    - **ThreatID** / **VulnID**: The identifier for the threat/vulnerability.\n",
    "    - **Threat** / **Vulnerability**: The name of the threat/vulnerability.\n",
    "    - **Description**: A detailed explanation of the threat/vulnerability.\n",
    "\n",
    "    **If no threats or vulnerabilities apply**, respond with an empty array for that category.\n",
    "    \"Generate a JSON object with the following information.\"\n",
    "    ### **Format of the Response:**\n",
    "        {{\n",
    "            \"ScenarioID\": \"[Scenario ID]\",\n",
    "            \"Threats\": [\n",
    "                {{\n",
    "                    \"ThreatID\": \"[Threat ID]\",\n",
    "                    \"Threat\": \"[Threat Name]\",\n",
    "                    \"Description\": \"[Threat Description]\"\n",
    "                }}\n",
    "            ]\n",
    "            \n",
    "        }}\n",
    "        \"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def generate_prompts_for_all_scenarios(scenarios_df, threats_df, vulnerabilities_df):\n",
    "    \"\"\"\n",
    "    Generate LLM prompts for all scenarios in the CSV.\n",
    "\n",
    "    Args:\n",
    "        scenarios_df (pd.DataFrame): DataFrame containing scenarios.\n",
    "        threats_df (pd.DataFrame): DataFrame containing threats.\n",
    "        vulnerabilities_df (pd.DataFrame): DataFrame containing vulnerabilities.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of prompts for each scenario.\n",
    "    \"\"\"\n",
    "    prompts = []\n",
    "    for scenario_id in scenarios_df['Scenario ID']:\n",
    "        prompt = generate_llm_prompt(scenario_id, scenarios_df, threats_df, vulnerabilities_df)\n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    return prompts\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Load the CSV files into DataFrames with the correct delimiter (semicolon)\n",
    "scenarios_df = pd.read_csv('scen1.csv', delimiter=';')\n",
    "threats_df = pd.read_csv('threat.csv', delimiter=';')\n",
    "vulnerabilities_df = pd.read_csv('vulnerability.csv', delimiter=';')\n",
    "\n",
    "# Clean the column names (strip spaces)\n",
    "scenarios_df.columns = scenarios_df.columns.str.strip()\n",
    "threats_df.columns = threats_df.columns.str.strip()\n",
    "vulnerabilities_df.columns = vulnerabilities_df.columns.str.strip()\n",
    "\n",
    "# Generate prompts for all scenarios\n",
    "prompts = generate_prompts_for_all_scenarios(scenarios_df, threats_df, vulnerabilities_df)\n",
    "\n",
    "# Print the first generated prompt as an example\n",
    "print(prompts[0])  # Example: Print the first prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "Answer: Lets think stpe by step\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = OllamaLLM(model=\"marco-o1\")\n",
    "chain = prompt | model\n",
    "answer = (chain.invoke({\"question\": prompts[0]}))\n",
    "print(answer)\n",
    "\n",
    "csv_filename = \"answers.csv\"\n",
    "\n",
    "with open(csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([answer])  # Writing question-answer pair\n",
    "\n",
    "print(f\"Answer saved to {csv_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
