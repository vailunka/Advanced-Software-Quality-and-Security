{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain-ollama\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of unique scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "scenarios_file = \"scenarios.csv\"\n",
    "unique_scenarios_file = \"scenarios_unique.csv\"\n",
    "\n",
    "def select_unique_scenarios(input, output):\n",
    "    \"\"\"Selecting unique scenarios for creating prompt\"\"\"\n",
    "\n",
    "    df = pd.read_csv(input, delimiter=\";\")\n",
    "    df['Scenario ID'] = df['Scenario ID'].str.strip()\n",
    "    df['User'] = df['User'].str.strip()\n",
    "\n",
    "    unique = df.drop_duplicates(subset=['Scenario ID'], keep='first')[\n",
    "        ['Scenario ID', 'User']]\n",
    "   \n",
    "    unique.to_csv(output, index=False, sep=\";\")\n",
    "\n",
    "    print(f\"Unique scenarios saved to {output}\")\n",
    "\n",
    "\n",
    "select_unique_scenarios(scenarios_file, unique_scenarios_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input and output files\n",
    "original_df = pd.read_csv(scenarios_file, delimiter=\";\")\n",
    "result_df = pd.read_csv(unique_scenarios_file, delimiter=\";\")\n",
    "\n",
    "# Clean input just like in the function\n",
    "original_df['Scenario ID'] = original_df['Scenario ID'].str.strip()\n",
    "original_df['User'] = original_df['User'].str.strip()\n",
    "\n",
    "# Build expected DataFrame\n",
    "expected_df = original_df.drop_duplicates(subset=['Scenario ID'], keep='first')[['Scenario ID', 'User']]\n",
    "\n",
    "# Strip result again just in case\n",
    "result_df['Scenario ID'] = result_df['Scenario ID'].str.strip()\n",
    "result_df['User'] = result_df['User'].str.strip()\n",
    "\n",
    "# Compare\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(result_df.reset_index(drop=True), expected_df.reset_index(drop=True))\n",
    "    print(\"✅ Test passed: Output matches expected unique scenarios.\")\n",
    "except AssertionError as e:\n",
    "    print(\"❌ Test failed:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_llm_prompt(scenario_id, scenarios_df, threats_df, vulnerabilities_df):\n",
    "    \"\"\"\n",
    "    Generates a formatted LLM prompt based on the given scenario, threats, and vulnerabilities.\n",
    "    \n",
    "    Args:\n",
    "        scenario_id (str): The scenario ID to pull the correct description.\n",
    "        scenarios_df (pd.DataFrame): DataFrame containing scenarios data.\n",
    "        threats_df (pd.DataFrame): DataFrame containing threat data.\n",
    "        vulnerabilities_df (pd.DataFrame): DataFrame containing vulnerability data.\n",
    "        \n",
    "    Returns:\n",
    "        str: The LLM prompt formatted as a string.\n",
    "    \"\"\"\n",
    "    scenario_row = scenarios_df[scenarios_df['Scenario ID'] == scenario_id]\n",
    "    if not scenario_row.empty:\n",
    "        scenario_description = scenario_row['User'].iloc[0] \n",
    "    else:\n",
    "        print(f\"No scenario found with ID: {scenario_id}\")\n",
    "    \n",
    "    risk_description = scenario_row['Assistant - Risk description'] if 'Assistant - Risk description' in scenario_row else \"No risk description available.\"\n",
    "    vulnerability_description = scenario_row['Assistant - Vulnerability description'] if 'Assistant - Vulnerability description' in scenario_row else \"No vulnerability description available.\"\n",
    "    \n",
    "    threats_text = \"\\n\\n\".join([\n",
    "    f\"ThreatID: {row['THREAT ID']}\\n\"\n",
    "    f\"ThreatName: {row['THREAT']}\\n\"\n",
    "    f\"ThreatDescription: {row['DESCRIPTION']}\\n\"\n",
    "    \"---------------------------------\"  \n",
    "    for _, row in threats_df.iterrows()\n",
    "])\n",
    "\n",
    "    vulnerabilities_text = \"\\n\\n\".join([\n",
    "    f\"VulnID: {row['ID']}\\n\"\n",
    "    f\"VulnerabilityName: {row['VULNERABILITY']}\\n\"\n",
    "    f\"VulnDescription: {row['DESCRIPTION']}\\n\"\n",
    "    \"---------------------------------\"  \n",
    "    for _, row in vulnerabilities_df.iterrows()\n",
    "])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    \n",
    "    ROLE: You are an assistant specializing in security risk analysis. Your task is to assess the provided scenario and identify any potential threats from the given list.\n",
    "    Do not generate new threats. Use values that I provide\n",
    "\n",
    "### **Instructions:**\n",
    "\n",
    "1. **Read the scenario carefully.** This is the only scenario you need to evaluate. Do not invent any details or make assumptions. Always respond in English.\n",
    "\n",
    "    - ScenarioID: {scenario_id}\n",
    "    - Scenario description: \"{scenario_description}\"\n",
    "\n",
    "2. **Identify all the applicable threats.** Review the scenario and compare it against the \"Threats List\" below. If a security threat is present, please explain what the security threat is. Only choose threats that are exact matches from the list. Do not select any threats that are not in the provided list.\n",
    "    - **Threats List:**\n",
    "    {threats_text}\n",
    "\n",
    "    **DO NOT create new threats or mention anything outside of the provided Threats List.** If no threats apply, leave the \"Threats\" array empty.\n",
    "\n",
    "3. **Create a new JSON object for every threat you find.** For each identified threat, create a JSON object with the following format:\n",
    "\n",
    "    {{\n",
    "        \"ScenarioID\": \"{scenario_id}\",\n",
    "        \"Scenario\": \"{scenario_description}\",\n",
    "        \"Threats\": [\n",
    "            {{\n",
    "                \"ThreatID\": \"<THREAT_ID>\",\n",
    "                \"ThreatName\": \"<THREAT_NAME>\",\n",
    "                \"ThreatDescription\": \"<THREAT_DESCRIPTION>\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "\n",
    "    **For Example**\n",
    "    {{\n",
    "        \"ScenarioID\": \"{scenario_id}\",\n",
    "        \"Scenario\": \"{scenario_description}\",\n",
    "        \"Threats\": [\n",
    "            {{\n",
    "                \"ThreatID\": \"T2\"\n",
    "                \"ThreatName\": \"Power supply\"\n",
    "                \"ThreatDescription\": \"Power failure to devices which may cause loss or corruption of processed data\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "\n",
    "\n",
    "    - Ensure that Threats matches list i provided.\n",
    "\n",
    "    ### **Important Notes:**\n",
    "    - **Do not** generate new threats. Use only the values provided in the \"Threats List\".\n",
    "    - Ensure that the JSON output is valid and correctly formatted.\n",
    "    \"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def generate_prompts_for_all_scenarios(scenarios_df, threats_df, vulnerabilities_df):\n",
    "    \"\"\"\n",
    "    Generate LLM prompts for all scenarios in the CSV.\n",
    "\n",
    "    Args:\n",
    "        scenarios_df (pd.DataFrame): DataFrame containing scenarios.\n",
    "        threats_df (pd.DataFrame): DataFrame containing threats.\n",
    "        vulnerabilities_df (pd.DataFrame): DataFrame containing vulnerabilities.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of prompts for each scenario.\n",
    "    \"\"\"\n",
    "    prompts = []\n",
    "    for scenario_id in scenarios_df['Scenario ID']:\n",
    "        prompt = generate_llm_prompt(scenario_id, scenarios_df, threats_df, vulnerabilities_df)\n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    return prompts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scenarios_df = pd.read_csv(unique_scenarios_file, delimiter=';')\n",
    "threats_df = pd.read_csv('threat.csv', delimiter=';')\n",
    "vulnerabilities_df = pd.read_csv('vulnerability.csv', delimiter=';')\n",
    "\n",
    "scenarios_df.columns = scenarios_df.columns.str.strip()\n",
    "threats_df.columns = threats_df.columns.str.strip()\n",
    "vulnerabilities_df.columns = vulnerabilities_df.columns.str.strip()\n",
    "\n",
    "prompts = generate_prompts_for_all_scenarios(scenarios_df, threats_df, vulnerabilities_df)\n",
    "\n",
    "print(prompts[1])  # Example: Print the first prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "import csv\n",
    "\n",
    "answer_limit = 193\n",
    "csv_filename = \"answers.csv\"\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "Answer: Return only json\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def generate_answer_for_prompt(question):\n",
    "    \"\"\"Generates answer for single prompt\"\"\"\n",
    "    model = OllamaLLM(model=\"qwen2.5\")  \n",
    "    chain = prompt | model\n",
    "    answer = chain.invoke({\"question\": question})\n",
    "    return answer\n",
    "\n",
    "def generate_answers_for_all_prompts(prompts, limit, answer_file):\n",
    "    \"\"\"Generates answers for all the prompts created earlier\"\"\"\n",
    "    limit = min(limit, len(prompts))\n",
    "\n",
    "    for i in range(limit):\n",
    "        question = prompts[i]\n",
    "        answer = generate_answer_for_prompt(question)  \n",
    "\n",
    "        with open(answer_file, mode=\"a\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([answer]) \n",
    "\n",
    "        print(f\"Answer saved to {answer_file}\")\n",
    "\n",
    "\n",
    "generate_answers_for_all_prompts(prompts, answer_limit, csv_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import re\n",
    "\n",
    "input = \"answers.csv\"\n",
    "output = \"answer_in_csv.csv\"\n",
    "\n",
    "def json_to_csv(input_file, output_file):\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read().strip()\n",
    "\n",
    "    json_entries = re.findall(r'```json\\n(.*?)\\n```', content, re.DOTALL)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for json_str in json_entries:\n",
    "        try:\n",
    "            json_str = json_str.replace('\"\"', '\"')\n",
    "\n",
    "            parsed_data = json.loads(json_str)\n",
    "\n",
    "            scenario_id = parsed_data.get(\"ScenarioID\", \"\")\n",
    "            scenario = parsed_data.get(\"Scenario\", \"\")\n",
    "\n",
    "            if parsed_data.get(\"Threats\"):\n",
    "                for threat in parsed_data[\"Threats\"]:\n",
    "                    data.append([\n",
    "                        scenario_id,\n",
    "                        scenario,\n",
    "                        threat.get(\"ThreatID\", \"\"),\n",
    "                        threat.get(\"ThreatName\", \"\"),\n",
    "                        threat.get(\"ThreatDescription\", \"\")\n",
    "                    ])\n",
    "            else:\n",
    "                data.append([scenario_id, scenario, \"\", \"\", \"\"])  \n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Skipping invalid JSON: {json_str}\")\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file, delimiter=';')\n",
    "        writer.writerow([\"ScenarioID\", \"Scenario\", \"ThreatID\", \"ThreatName\", \"ThreatDescription\"])\n",
    "        writer.writerows(data)\n",
    "\n",
    "    print(f\"Formatted CSV file saved as {output_file}\")\n",
    "\n",
    "json_to_csv(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "def test_json_to_csv_creates_files_in_current_folder():\n",
    "    # Paths in current folder\n",
    "    input_path = \"test_input.json.txt\"\n",
    "    output_path = \"test_output.csv\"\n",
    "\n",
    "    # Simulated LLM-like input\n",
    "    json_text = \"\"\"\"```json\n",
    "{\n",
    "    \"\"ScenarioID\"\": \"\"S1\"\",\n",
    "    \"\"Scenario\"\": \"\"The processing center is located in the basement. A sewer system runs under the building. The walls of the room that houses the processing center are not reinforced.\"\",\n",
    "    \"\"Threats\"\": [\n",
    "        {\n",
    "            \"\"ThreatID\"\": \"\"T3\"\",\n",
    "            \"\"ThreatName\"\": \"\"Flooding\"\",\n",
    "            \"\"ThreatDescription\"\": \"\"Flooding of the rooms where the systems and/or storage media are located\"\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\"\n",
    "\"```json\n",
    "{\n",
    "    \"\"ScenarioID\"\": \"\"S2\"\",\n",
    "    \"\"Scenario\"\": \"\"Confidential documents are stored in an archive constantly protected by armed guards, with three levels of biometric protection. The room that houses the archive is reinforced and burglar-proof.\"\",\n",
    "    \"\"Threats\"\": [\n",
    "    ]\n",
    "}\n",
    "```\"\n",
    "\"```json\"\"\"\n",
    "\n",
    "    # Write the test input file\n",
    "    with open(input_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(json_text)\n",
    "\n",
    "    # Run the function\n",
    "    json_to_csv(input_path, output_path)\n",
    "\n",
    "    # Load and check output CSV\n",
    "    df = pd.read_csv(output_path, delimiter=';')\n",
    "\n",
    "    assert len(df) == 2\n",
    "    assert df.loc[0, \"ScenarioID\"] == \"S1\"\n",
    "    assert df.loc[0, \"ThreatID\"] == \"T3\"\n",
    "    assert df.loc[1, \"ScenarioID\"] == \"S2\"\n",
    "    assert df.loc[1, [\"ThreatID\", \"ThreatName\", \"ThreatDescription\"]].isna().all()\n",
    "\n",
    "\n",
    "    print(\"✅ Test passed: CSV output correctly extracted threat data and saved to current folder.\")\n",
    "\n",
    "# 🔥 Run the test\n",
    "test_json_to_csv_creates_files_in_current_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_llm_prompt1(scenario_id, scenarios_df, vulnerabilities_df):\n",
    "    \"\"\"\n",
    "    Generates a formatted LLM prompt based on the given scenario, pre-identified threats, and possible vulnerabilities.\n",
    "\n",
    "    Args:\n",
    "        scenario_id (str): The scenario ID to pull the correct description.\n",
    "        scenarios_df (pd.DataFrame): DataFrame containing scenarios and threats.\n",
    "        vulnerabilities_df (pd.DataFrame): DataFrame containing vulnerability data.\n",
    "\n",
    "    Returns:\n",
    "        str: The LLM prompt formatted as a string.\n",
    "    \"\"\"\n",
    "    \n",
    "    scenario_row = scenarios_df[scenarios_df['ScenarioID'] == scenario_id]\n",
    "    if not scenario_row.empty:\n",
    "        scenario_description = scenario_row['Scenario'].iloc[0]\n",
    "        threat_id = scenario_row['ThreatID'].iloc[0]\n",
    "        threat_name = scenario_row['ThreatName'].iloc[0]\n",
    "        threat_description = scenario_row['ThreatDescription'].iloc[0]\n",
    "    else:\n",
    "        print(f\"No scenario found with ID: {scenario_id}\")\n",
    "        return None \n",
    "\n",
    "    \n",
    "    vulnerabilities_text = \"\\n\\n\".join([\n",
    "        f\"VulnID: {row['ID']}\\n\"\n",
    "        f\"VulnerabilityName: {row['VULNERABILITY']}\\n\"\n",
    "        f\"VulnDescription: {row['DESCRIPTION']}\\n\"\n",
    "        \"---------------------------------\"\n",
    "        for _, row in vulnerabilities_df.iterrows()\n",
    "    ])\n",
    "\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    ROLE: You are an assistant specializing in security risk analysis. Your task is to assess the provided scenario and identify any applicable **vulnerabilities** from the given list.\n",
    "    The threats have already been identified.\n",
    "\n",
    "### **Instructions:**\n",
    "\n",
    "1. **Read the scenario carefully.** This is the only scenario you need to evaluate. Do not invent any details or make assumptions. Always respond in English.\n",
    "\n",
    "    - ScenarioID: {scenario_id}\n",
    "    - Scenario description: \"{scenario_description}\"\n",
    "\n",
    "2. **This is the already identified threat for this scenario:**\n",
    "    ThreatID: {threat_id}\n",
    "    ThreatName: {threat_name}\n",
    "    ThreatDescription: {threat_description}\n",
    "\n",
    "3. **Identify all the applicable vulnerabilities.** Review the scenario and compare it against the \"Vulnerabilities List\" below. If a vulnerability is present, explain why it applies. Only select vulnerabilities that match exactly from the provided list.\n",
    "    - **Vulnerabilities List:**\n",
    "    {vulnerabilities_text}\n",
    "\n",
    "    **DO NOT create new vulnerabilities or mention anything outside of the provided list.** If no vulnerabilities apply, leave the \"Vulnerabilities\" array empty.\n",
    "\n",
    "4. **Create a new JSON object for every identified vulnerability**, using the following format:\n",
    "\n",
    "    {{\n",
    "        \"ScenarioID\": \"{scenario_id}\",\n",
    "        \"Scenario\": \"{scenario_description}\",    \n",
    "        \"ThreatID\": \"{threat_id}\",\n",
    "        \"ThreatName\": \"{threat_name}\",\n",
    "        \"ThreatDescription\": \"{threat_description}\"\n",
    "        \"Vulnerabilities\": [\n",
    "            {{\n",
    "                \"VulnID\": \"<VULN_ID>\",\n",
    "                \"VulnerabilityName\": \"<VULNERABILITY_NAME>\",\n",
    "                \"VulnDescription\": \"<VULN_DESCRIPTION>\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "\n",
    "    **Example Output**\n",
    "    {{\n",
    "        \"ScenarioID\": \"{scenario_id}\",\n",
    "        \"Scenario\": \"{scenario_description}\",    \n",
    "        \"ThreatID\": \"{threat_id}\",\n",
    "        \"ThreatName\": \"{threat_name}\",\n",
    "        \"ThreatDescription\": \"{threat_description}\"\n",
    "        \"Vulnerabilities\": [\n",
    "            {{\n",
    "                \"VulnID\": \"V1\",\n",
    "                \"VulnerabilityName\": \"Communication channels not adequately protected\",\n",
    "                \"VulnDescription\": \"Channels (carrying classified/sensitive corporate data) not subject to security procedures (encryption devices) or not physically inaccessible (e.g. connections with accessible data cables, to which interception tools can be connected)\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "\n",
    "    - Ensure that **vulnerabilities match exactly** from the provided list.\n",
    "\n",
    "### **Important Notes:**\n",
    "- **Do not** generate new vulnerabilities. Use only the values provided in the \"Vulnerabilities List\".\n",
    "- Ensure that the JSON output is valid and correctly formatted.\n",
    "\"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def generate_prompts_for_all_scenarios1(scenarios_df, vulnerabilities_df):\n",
    "    \"\"\"\n",
    "    Generate LLM prompts for all scenarios.\n",
    "\n",
    "    Args:\n",
    "        scenarios_df (pd.DataFrame): DataFrame containing scenarios and threats.\n",
    "        vulnerabilities_df (pd.DataFrame): DataFrame containing vulnerabilities.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of prompts for each scenario.\n",
    "    \"\"\"\n",
    "    prompts = []\n",
    "    for scenario_id in scenarios_df['ScenarioID']:\n",
    "        prompt = generate_llm_prompt1(scenario_id, scenarios_df, vulnerabilities_df)\n",
    "        if prompt:  \n",
    "            prompts.append(prompt)\n",
    "    \n",
    "    return prompts\n",
    "\n",
    "\n",
    "\n",
    "scenarios_df = pd.read_csv(\"formatted_answer.csv\", delimiter=';')\n",
    "vulnerabilities_df = pd.read_csv(\"vulnerability.csv\", delimiter=';')\n",
    "\n",
    "\n",
    "scenarios_df.columns = scenarios_df.columns.str.strip()\n",
    "vulnerabilities_df.columns = vulnerabilities_df.columns.str.strip()\n",
    "\n",
    "\n",
    "prompts_vulnerabilties = generate_prompts_for_all_scenarios1(scenarios_df, vulnerabilities_df)\n",
    "\n",
    "\n",
    "print(prompts_vulnerabilties[0])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "import csv\n",
    "\n",
    "\n",
    "answer_limit = len(prompts_vulnerabilties)  \n",
    "csv_filename = \"answers1.csv\"  \n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "Answer: Return only JSON\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def generate_answer_for_prompt1(question):\n",
    "    \"\"\"\n",
    "    Invokes the LLM with a given question prompt and returns the JSON answer.\n",
    "    \"\"\"\n",
    "    model = OllamaLLM(model=\"qwen2.5\")  \n",
    "    chain = prompt | model\n",
    "    answer = chain.invoke({\"question\": question}) \n",
    "    return answer\n",
    "\n",
    "def generate_answers_for_all_prompts1(prompts, limit, answer_file):\n",
    "    \"\"\"\n",
    "    Iterates through a list of prompts, gets responses from the LLM, and stores them in a CSV file.\n",
    "    \"\"\"\n",
    "    limit = min(limit, len(prompts))\n",
    "\n",
    "    for i in range(limit):\n",
    "        question = prompts[i]  \n",
    "        answer = generate_answer_for_prompt1(question)  \n",
    "\n",
    "        with open(answer_file, mode=\"a\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([answer]) \n",
    "\n",
    "        print(f\"Answer saved to {answer_file}\")\n",
    "\n",
    "generate_answers_for_all_prompts1(prompts_vulnerabilties, answer_limit, csv_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import re\n",
    "\n",
    "input = \"answers1.csv\" \n",
    "output = \"final_formatted_answers_to_csv.csv\"\n",
    "\n",
    "def json_to_csv2(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Creates a CSV file for each scenarios and its vulnerabilities and threats\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read().strip()\n",
    "\n",
    "    json_entries = re.findall(r'```json\\n(.*?)\\n```', content, re.DOTALL)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for json_str in json_entries:\n",
    "        try:\n",
    "            json_str = json_str.replace('\"\"', '\"')\n",
    "\n",
    "            parsed_data = json.loads(json_str)\n",
    "\n",
    "            scenario_id = parsed_data.get(\"ScenarioID\", \"\")\n",
    "            scenario_desc = parsed_data.get(\"Scenario\", \"\")\n",
    "            threat_id = parsed_data.get(\"ThreatID\", \"\")\n",
    "            threat_name = parsed_data.get(\"ThreatName\", \"\")\n",
    "            threat_desc = parsed_data.get(\"ThreatDescription\", \"\")\n",
    "\n",
    "            if \"Vulnerabilities\" in parsed_data and parsed_data[\"Vulnerabilities\"]:\n",
    "                for vuln in parsed_data[\"Vulnerabilities\"]:\n",
    "                    data.append([\n",
    "                        scenario_id,\n",
    "                        scenario_desc,\n",
    "                        threat_id,\n",
    "                        threat_name,\n",
    "                        threat_desc,\n",
    "                        vuln.get(\"VulnID\", \"\"),\n",
    "                        vuln.get(\"VulnerabilityName\", \"\"),\n",
    "                        vuln.get(\"VulnDescription\", \"\")\n",
    "                    ])\n",
    "            else:\n",
    "                data.append([scenario_id, scenario_desc, threat_id, threat_name, threat_desc, \"\", \"\", \"\"])\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Skipping invalid JSON: {json_str}\")\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file, delimiter=';')\n",
    "        writer.writerow([\n",
    "            \"ScenarioID\", \"Scenario\", \"ThreatID\", \"ThreatName\", \"ThreatDescription\",\n",
    "            \"VulnID\", \"VulnerabilityName\", \"VulnDescription\"\n",
    "        ])\n",
    "        writer.writerows(data)\n",
    "\n",
    "    print(f\"Formatted CSV file saved as {output_file}\")\n",
    "\n",
    "json_to_csv2(input, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_json_to_csv2_creates_file_with_vulns_and_no_vulns():\n",
    "    input_path = \"test_answers.json.txt\"\n",
    "    output_path = \"test_formatted_output.csv\"\n",
    "\n",
    "    json_content = \"\"\"\"```json\n",
    "{\n",
    "    \"\"ScenarioID\"\": \"\"S1\"\",\n",
    "    \"\"Scenario\"\": \"\"The processing center is located in the basement. A sewer system runs under the building. The walls of the room that houses the processing center are not reinforced.\"\",    \n",
    "    \"\"ThreatID\"\": \"\"T3\"\",\n",
    "    \"\"ThreatName\"\": \"\"Flooding\"\",\n",
    "    \"\"ThreatDescription\"\": \"\"Flooding of the rooms where the systems and/or storage media are located\"\",\n",
    "    \"\"Vulnerabilities\"\": [\n",
    "        {\n",
    "            \"\"VulnID\"\": \"\"V26\"\",\n",
    "            \"\"VulnerabilityName\"\": \"\"Inadequate fire protection\"\",\n",
    "            \"\"VulnDescription\"\": \"\"Lack of a specific fire protection system to safeguard the system and the data contained within it (e.g. fireproof safes and automatic shutdown system)\"\"\n",
    "        },\n",
    "        {\n",
    "            \"\"VulnID\"\": \"\"V27\"\",\n",
    "            \"\"VulnerabilityName\"\": \"\"Inadequate flood protection\"\",\n",
    "            \"\"VulnDescription\"\": \"\"Lack of a specific anti-flooding system to safeguard the system and the data contained within it (e.g. watertight bulkheads)\"\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\"\"\"\n",
    "\n",
    "    with open(input_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(json_content)\n",
    "\n",
    "    json_to_csv2(input_path, output_path)\n",
    "\n",
    "    df = pd.read_csv(output_path, delimiter=';')\n",
    "    assert len(df) == 2\n",
    "    assert df.loc[0, \"ScenarioID\"] == \"S1\"\n",
    "    assert df.loc[0, \"VulnID\"] == \"V26\"\n",
    "    assert df.loc[1, \"VulnID\"] == \"V27\"\n",
    "\n",
    "    print(\"✅ Test passed: json_to_csv2 correctly parsed vulnerabilities and empty cases.\")\n",
    "\n",
    "test_json_to_csv2_creates_file_with_vulns_and_no_vulns()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
